{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrnbvOcvn44w"
   },
   "source": [
    "This is a Google Colab notebook which installs appropriate PyTorch v1 according to the system architecture and the GPU available.\n",
    "\n",
    "If you come across any issues, then feel free to contact me on Slack. My username is ***avinashss***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RtN00cb0n6hZ",
    "outputId": "41443ebf-f9a0-4f92-c692-4799eafadd9a"
   },
   "outputs": [],
   "source": [
    "# google colab does not come with torch installed. And also, in lesson we are \n",
    "# using torch v1.0 \n",
    "# so following snippet of code installs the relevant version according to the \n",
    "# GPU architecture\n",
    "!pip install -q torch==1.1.0 torchvision\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jW9T-evMrqds",
    "outputId": "bc49ece5-6401-4308-e722-ddbddc7789c3"
   },
   "outputs": [],
   "source": [
    "# we will verify that GPU is enabled for this notebook\n",
    "# following should print: CUDA is available!  Training on GPU ...\n",
    "# \n",
    "# if it prints otherwise, then you need to enable GPU: \n",
    "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "tKQGml-R_jxP",
    "outputId": "4ca7e20b-8aea-4032-9d52-b1ee9804064f"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VA32GQtL_sS4"
   },
   "outputs": [],
   "source": [
    "import torch, argparse\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4AroTSe_ymC"
   },
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    BCE = F.mse_loss(recon_x, x)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VsgYfMLAFYI"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_dims=784, hid_dims=100, negative_slope=0.1):\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(OrderedDict([\n",
    "            ('layer1', nn.Linear(in_dims, 512)),\n",
    "            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n",
    "            ('layer2', nn.Linear(512, 256)),\n",
    "            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n",
    "            ('layer3', nn.Linear(256, 128)),\n",
    "            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n",
    "        ]))\n",
    "        self.fc_mu = nn.Linear(128, hid_dims)\n",
    "        self.fc_var = nn.Linear(128, hid_dims)\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(OrderedDict([\n",
    "            ('layer1', nn.Linear(hid_dims, 128)),\n",
    "            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n",
    "            ('layer2', nn.Linear(128, 256)),\n",
    "            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n",
    "            ('layer3', nn.Linear(256, 512)),\n",
    "            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),\n",
    "            ('layer4', nn.Linear(512, in_dims)),\n",
    "            ('sigmoid', nn.Sigmoid()),\n",
    "        ]))\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            h = self.encoder(x)\n",
    "            mu, logvar = self.fc_mu(h), self.fc_var(h)\n",
    "            z = self._reparameterize(mu, logvar)\n",
    "            y = self.decoder(z)\n",
    "            return y, mu, logvar\n",
    "        else:\n",
    "            z = self.represent(x)\n",
    "            y = self.decoder(z)\n",
    "            return y\n",
    "\n",
    "    def represent(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = self.fc_mu(h), self.fc_var(h)\n",
    "        z = self._reparameterize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def _reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        esp = torch.randn(*mu.size()).type_as(mu)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dGYdTmNJAOIJ"
   },
   "outputs": [],
   "source": [
    "class ImproveChecker():\n",
    "\tdef __init__(self, mode='min', best_val=None):\n",
    "\t\tassert mode in ['min', 'max']\n",
    "\t\tself.mode = mode\n",
    "\t\tif best_val is not None:\n",
    "\t\t\tself.best_val = best_val\n",
    "\t\telse:\n",
    "\t\t\tif self.mode=='min':\n",
    "\t\t\t\tself.best_val = np.inf\n",
    "\t\t\telif self.mode=='max':\n",
    "\t\t\t\tself.best_val = 0.0\n",
    "\n",
    "\tdef check(self, val):\n",
    "\t\tif self.mode=='min':\n",
    "\t\t\tif val < self.best_val:\n",
    "\t\t\t\tprint(\"[%s] Improved from %.4f to %.4f\" % (self.__class__.__name__, self.best_val, val))\n",
    "\t\t\t\tself.best_val = val\n",
    "\t\t\t\treturn True\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"[%s] Not improved from %.4f\" % (self.__class__.__name__, self.best_val))\n",
    "\t\t\t\treturn False\n",
    "\t\telse:\n",
    "\t\t\tif val > self.best_val:\n",
    "\t\t\t\tprint(\"[%s] Improved from %.4f to %.4f\" % (self.__class__.__name__, self.best_val, val))\n",
    "\t\t\t\tself.best_val = val\n",
    "\t\t\t\treturn True\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"[%s] Not improved from %.4f\" % (self.__class__.__name__, self.best_val))\n",
    "\t\t\t\treturn False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "1Tpp1zrfAQoK",
    "outputId": "b4c298cf-3d96-4641-ad5f-d34336713d97"
   },
   "outputs": [],
   "source": [
    "# Initialize VAE\n",
    "model = VAE(in_dims=784, hid_dims=100)\n",
    "model.cuda()\n",
    "\n",
    "# Configure data loader\n",
    "dataset = datasets.MNIST(root='.', train=True, download=True,\n",
    "\ttransform=transforms.Compose([\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Normalize((0.1307,), (0.3081,))\n",
    "]))\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "\tdataset, batch_size=128,\n",
    "\tnum_workers=4, shuffle=True, pin_memory=True,\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ImproveChecker\n",
    "improvechecker = ImproveChecker(mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1496
    },
    "colab_type": "code",
    "id": "dWLyITDvAge0",
    "outputId": "324b96d1-e464-43ce-ff5f-652d10e36c92"
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(1, 301):\n",
    "\tfor i, (imgs, _) in enumerate(dataloader):\n",
    "\t\t# Prepare input\n",
    "\t\tinputs = imgs.view(imgs.shape[0], -1)\n",
    "\t\tinputs = inputs.cuda()\n",
    "\n",
    "\t\t# Train\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs, mu, logvar = model(inputs)\n",
    "\t\tloss = loss_fn(outputs, inputs, mu, logvar)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t# ImproveChecker\n",
    "\tprint(\"[EPOCH %.3d] Loss: %.6f\" % (epoch, loss.item()))\n",
    "\tif improvechecker.check(loss.item()):\n",
    "\t\tcheckpoint = dict(\n",
    "\t\t\tepoch=epoch,\n",
    "\t\t\tloss=loss.item(),\n",
    "\t\t\tstate_dict=model.state_dict(),\n",
    "\t\t\toptimizer=optimizer.state_dict(),\n",
    "\t\t)\n",
    "\t\tsave_file = os.path.join('.', \"vae.pth\")\n",
    "\t\ttorch.save(checkpoint, save_file)\n",
    "\t\tprint(\"Best checkpoint is saved at %s\" % (save_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VAE-MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
